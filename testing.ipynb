{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebfd717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import MCPStdioTool, MCPStreamableHTTPTool, MCPStdioTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70fa7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = MCPStreamableHTTPTool(\n",
    "            name=\"Microsoft Learn MCP\",\n",
    "            url=\"https://learn.microsoft.com/api/mcp\",\n",
    "            # we don't require approval for microsoft_docs_search tool calls\n",
    "            # but we do for any other tool\n",
    "            # approval_mode={\"never_require_approval\": [\"microsoft_docs_search\"]},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa369a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2 = MCPStdioTool(  \n",
    "    name=\"filesystem\",  \n",
    "    command=\"npx\",  \n",
    "    args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", r\"C:\\Users\\blain\\Documents\"],  \n",
    "    description=\"File system operations\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9f02bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool3 = MCPStreamableHTTPTool(\n",
    "            name=\"localhost MCP\",\n",
    "            url=\"http://localhost:1337/mcp\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "947f4ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \n",
      "\n",
      "=== HTTP Request/Response Details Below ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"initialize\",\n",
      "  \"params\": {\n",
      "    \"protocolVersion\": \"2025-06-18\",\n",
      "    \"capabilities\": {\n",
      "      \"sampling\": {}\n",
      "    },\n",
      "    \"clientInfo\": {\n",
      "      \"name\": \"mcp\",\n",
      "      \"version\": \"0.1.0\"\n",
      "    }\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 0\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"initialize\",\n",
      "  \"params\": {\n",
      "    \"protocolVersion\": \"2025-06-18\",\n",
      "    \"capabilities\": {\n",
      "      \"sampling\": {}\n",
      "    },\n",
      "    \"clientInfo\": {\n",
      "      \"name\": \"mcp\",\n",
      "      \"version\": \"0.1.0\"\n",
      "    }\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 0\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":0,\"result\":{\"protocolVersion\":\"2025-06-18\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":true},\"resources\":{\"subscribe\":false,\"listChanged\":true},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"file_read\",\"version\":\"2.13.0.2\"}}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"notifications/initialized\",\n",
      "  \"jsonrpc\": \"2.0\"\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: GET http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body: <empty>\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 202 Accepted\"\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":0,\"result\":{\"protocolVersion\":\"2025-06-18\",\"capabilities\":{\"experimental\":{},\"prompts\":{\"listChanged\":true},\"resources\":{\"subscribe\":false,\"listChanged\":true},\"tools\":{\"listChanged\":true}},\"serverInfo\":{\"name\":\"file_read\",\"version\":\"2.13.0.2\"}}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"notifications/initialized\",\n",
      "  \"jsonrpc\": \"2.0\"\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: GET http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body: <empty>\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 202 Accepted\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 202: \n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/list\",\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 1\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"tools\":[{\"name\":\"list_files\",\"description\":\"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\"inputSchema\":{\"properties\":{},\"type\":\"object\"},\"outputSchema\":{\"properties\":{\"result\":{\"type\":\"string\"}},\"required\":[\"result\"],\"type\":\"object\",\"x-fastmcp-wrap-result\":true},\"_meta\":{\"_fastmcp\":{\"tags\":[]}}},{\"name\":\"read_file\",\"description\":\"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\"inputSchema\":{\"properties\":{\"filename\":{\"type\":\"string\"}},\"required\":[\"filename\"],\"type\":\"object\"},\"outputSchema\":{\"properties\":{\"result\":{\"type\":\"string\"}},\"required\":[\"result\"],\"type\":\"object\",\"x-fastmcp-wrap-result\":true},\"_meta\":{\"_fastmcp\":{\"tags\":[]}}}]}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] \tResponse 202: \n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/list\",\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 1\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"tools\":[{\"name\":\"list_files\",\"description\":\"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\"inputSchema\":{\"properties\":{},\"type\":\"object\"},\"outputSchema\":{\"properties\":{\"result\":{\"type\":\"string\"}},\"required\":[\"result\"],\"type\":\"object\",\"x-fastmcp-wrap-result\":true},\"_meta\":{\"_fastmcp\":{\"tags\":[]}}},{\"name\":\"read_file\",\"description\":\"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\"inputSchema\":{\"properties\":{\"filename\":{\"type\":\"string\"}},\"required\":[\"filename\"],\"type\":\"object\"},\"outputSchema\":{\"properties\":{\"result\":{\"type\":\"string\"}},\"required\":[\"result\"],\"type\":\"object\",\"x-fastmcp-wrap-result\":true},\"_meta\":{\"_fastmcp\":{\"tags\":[]}}}]}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"prompts/list\",\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 2\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\"prompts\":[]}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"prompts/list\",\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 2\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":2,\"result\":{\"prompts\":[]}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: GET http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - _client] HTTP Request: GET http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-519\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531526,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\",\n",
      "        \"reasoning\": \"The user requests: \\\"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog.\\\" We need to read the files. We must list files, then read file contents. We assume file names are file1.txt file2.txt? The wording is \\\"file 1\\\" and \\\"file 2\\\". We need to open those and check content. So we must use list_files, then read_file for each. Probably files are named file1.txt and file2.txt. We'll use read_file function.\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_4orvgk3x\",\n",
      "            \"index\": 0,\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"list_files\",\n",
      "              \"arguments\": \"{}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 254,\n",
      "    \"completion_tokens\": 131,\n",
      "    \"total_tokens\": 385\n",
      "  }\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"list_files\",\n",
      "    \"arguments\": {}\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 3\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-519\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531526,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\",\n",
      "        \"reasoning\": \"The user requests: \\\"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog.\\\" We need to read the files. We must list files, then read file contents. We assume file names are file1.txt file2.txt? The wording is \\\"file 1\\\" and \\\"file 2\\\". We need to open those and check content. So we must use list_files, then read_file for each. Probably files are named file1.txt and file2.txt. We'll use read_file function.\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_4orvgk3x\",\n",
      "            \"index\": 0,\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"list_files\",\n",
      "              \"arguments\": \"{}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 254,\n",
      "    \"completion_tokens\": 131,\n",
      "    \"total_tokens\": 385\n",
      "  }\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"list_files\",\n",
      "    \"arguments\": {}\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 3\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":3,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"file1.txt\\nfile10.txt\\nfile2.txt\\nfile3.txt\\nfile4.txt\\nfile5.txt\\nfile6.txt\\nfile7.txt\\nfile8.txt\\nfile9.txt\"}],\"structuredContent\":{\"result\":\"file1.txt\\nfile10.txt\\nfile2.txt\\nfile3.txt\\nfile4.txt\\nfile5.txt\\nfile6.txt\\nfile7.txt\\nfile8.txt\\nfile9.txt\"},\"isError\":false}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_4orvgk3x\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"list_files\",\n",
      "            \"arguments\": \"{}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_4orvgk3x\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"file1.txt\\\\nfile10.txt\\\\nfile2.txt\\\\nfile3.txt\\\\nfile4.txt\\\\nfile5.txt\\\\nfile6.txt\\\\nfile7.txt\\\\nfile8.txt\\\\nfile9.txt\\\"}]\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":3,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"file1.txt\\nfile10.txt\\nfile2.txt\\nfile3.txt\\nfile4.txt\\nfile5.txt\\nfile6.txt\\nfile7.txt\\nfile8.txt\\nfile9.txt\"}],\"structuredContent\":{\"result\":\"file1.txt\\nfile10.txt\\nfile2.txt\\nfile3.txt\\nfile4.txt\\nfile5.txt\\nfile6.txt\\nfile7.txt\\nfile8.txt\\nfile9.txt\"},\"isError\":false}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_4orvgk3x\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"list_files\",\n",
      "            \"arguments\": \"{}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_4orvgk3x\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"file1.txt\\\\nfile10.txt\\\\nfile2.txt\\\\nfile3.txt\\\\nfile4.txt\\\\nfile5.txt\\\\nfile6.txt\\\\nfile7.txt\\\\nfile8.txt\\\\nfile9.txt\\\"}]\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-997\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531526,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\",\n",
      "        \"reasoning\": \"We need to check file1.txt content for quick brown fox and file2.txt for lazy dog. We need to read those files.\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_byrn63ke\",\n",
      "            \"index\": 0,\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"read_file\",\n",
      "              \"arguments\": \"{\\\"filename\\\":\\\"file1.txt\\\"}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 331,\n",
      "    \"completion_tokens\": 53,\n",
      "    \"total_tokens\": 384\n",
      "  }\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"read_file\",\n",
      "    \"arguments\": {\n",
      "      \"filename\": \"file1.txt\"\n",
      "    }\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 4\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-997\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531526,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\",\n",
      "        \"reasoning\": \"We need to check file1.txt content for quick brown fox and file2.txt for lazy dog. We need to read those files.\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_byrn63ke\",\n",
      "            \"index\": 0,\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"read_file\",\n",
      "              \"arguments\": \"{\\\"filename\\\":\\\"file1.txt\\\"}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 331,\n",
      "    \"completion_tokens\": 53,\n",
      "    \"total_tokens\": 384\n",
      "  }\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"read_file\",\n",
      "    \"arguments\": {\n",
      "      \"filename\": \"file1.txt\"\n",
      "    }\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 4\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":4,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"The quick brown fox jumps over the lazy dog.\"}],\"structuredContent\":{\"result\":\"The quick brown fox jumps over the lazy dog.\"},\"isError\":false}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_4orvgk3x\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"list_files\",\n",
      "            \"arguments\": \"{}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_4orvgk3x\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"file1.txt\\\\nfile10.txt\\\\nfile2.txt\\\\nfile3.txt\\\\nfile4.txt\\\\nfile5.txt\\\\nfile6.txt\\\\nfile7.txt\\\\nfile8.txt\\\\nfile9.txt\\\"}]\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_byrn63ke\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"read_file\",\n",
      "            \"arguments\": \"{\\\"filename\\\":\\\"file1.txt\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_byrn63ke\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"The quick brown fox jumps over the lazy dog.\\\"}]\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":4,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"The quick brown fox jumps over the lazy dog.\"}],\"structuredContent\":{\"result\":\"The quick brown fox jumps over the lazy dog.\"},\"isError\":false}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_4orvgk3x\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"list_files\",\n",
      "            \"arguments\": \"{}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_4orvgk3x\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"file1.txt\\\\nfile10.txt\\\\nfile2.txt\\\\nfile3.txt\\\\nfile4.txt\\\\nfile5.txt\\\\nfile6.txt\\\\nfile7.txt\\\\nfile8.txt\\\\nfile9.txt\\\"}]\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_byrn63ke\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"read_file\",\n",
      "            \"arguments\": \"{\\\"filename\\\":\\\"file1.txt\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_byrn63ke\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"The quick brown fox jumps over the lazy dog.\\\"}]\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-448\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531527,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_aqm89fvv\",\n",
      "            \"index\": 0,\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"read_file\",\n",
      "              \"arguments\": \"{\\\"filename\\\":\\\"file2.txt\\\"}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 384,\n",
      "    \"completion_tokens\": 20,\n",
      "    \"total_tokens\": 404\n",
      "  }\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"read_file\",\n",
      "    \"arguments\": {\n",
      "      \"filename\": \"file2.txt\"\n",
      "    }\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 5\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-448\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531527,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"\",\n",
      "        \"tool_calls\": [\n",
      "          {\n",
      "            \"id\": \"call_aqm89fvv\",\n",
      "            \"index\": 0,\n",
      "            \"type\": \"function\",\n",
      "            \"function\": {\n",
      "              \"name\": \"read_file\",\n",
      "              \"arguments\": \"{\\\"filename\\\":\\\"file2.txt\\\"}\"\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      \"finish_reason\": \"tool_calls\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 384,\n",
      "    \"completion_tokens\": 20,\n",
      "    \"total_tokens\": 404\n",
      "  }\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://localhost:1337/mcp\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"read_file\",\n",
      "    \"arguments\": {\n",
      "      \"filename\": \"file2.txt\"\n",
      "    }\n",
      "  },\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 5\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://localhost:1337/mcp \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":5,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"Artificial intelligence is transforming the way we work.\"}],\"structuredContent\":{\"result\":\"Artificial intelligence is transforming the way we work.\"},\"isError\":false}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_4orvgk3x\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"list_files\",\n",
      "            \"arguments\": \"{}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_4orvgk3x\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"file1.txt\\\\nfile10.txt\\\\nfile2.txt\\\\nfile3.txt\\\\nfile4.txt\\\\nfile5.txt\\\\nfile6.txt\\\\nfile7.txt\\\\nfile8.txt\\\\nfile9.txt\\\"}]\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_byrn63ke\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"read_file\",\n",
      "            \"arguments\": \"{\\\"filename\\\":\\\"file1.txt\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_byrn63ke\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"The quick brown fox jumps over the lazy dog.\\\"}]\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_aqm89fvv\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"read_file\",\n",
      "            \"arguments\": \"{\\\"filename\\\":\\\"file2.txt\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_aqm89fvv\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"Artificial intelligence is transforming the way we work.\\\"}]\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: event: message\n",
      "data: {\"jsonrpc\":\"2.0\",\"id\":5,\"result\":{\"content\":[{\"type\":\"text\",\"text\":\"Artificial intelligence is transforming the way we work.\"}],\"structuredContent\":{\"result\":\"Artificial intelligence is transforming the way we work.\"},\"isError\":false}}\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_4orvgk3x\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"list_files\",\n",
      "            \"arguments\": \"{}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_4orvgk3x\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"file1.txt\\\\nfile10.txt\\\\nfile2.txt\\\\nfile3.txt\\\\nfile4.txt\\\\nfile5.txt\\\\nfile6.txt\\\\nfile7.txt\\\\nfile8.txt\\\\nfile9.txt\\\"}]\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_byrn63ke\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"read_file\",\n",
      "            \"arguments\": \"{\\\"filename\\\":\\\"file1.txt\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_byrn63ke\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"The quick brown fox jumps over the lazy dog.\\\"}]\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_aqm89fvv\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"read_file\",\n",
      "            \"arguments\": \"{\\\"filename\\\":\\\"file2.txt\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_aqm89fvv\",\n",
      "      \"content\": \"[{\\\"type\\\": \\\"text\\\", \\\"text\\\": \\\"Artificial intelligence is transforming the way we work.\\\"}]\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": false,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"list_files\",\n",
      "        \"description\": \"List all files in the files directory.\\n\\nReturns:\\n    A list of filenames in the files directory.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {},\n",
      "          \"title\": \"list_files_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"read_file\",\n",
      "        \"description\": \"Read the content of a file from the files directory.\\n\\nArgs:\\n    filename: Name of the file to read (e.g. file1.txt, file2.txt)\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"filename\": {\n",
      "              \"title\": \"Filename\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"filename\"\n",
      "          ],\n",
      "          \"title\": \"read_file_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-115\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531528,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"**Check results**\\n\\n| File | Content mention | Meets requirement? |\\n|------|-----------------|--------------------|\\n| **file1.txt** | \\u201cThe quick brown fox jumps over the lazy dog.\\u201d | \\u2714 **Yes \\u2013 it contains the quick\\u2011brown\\u2011fox reference** |\\n| **file2.txt** | \\u201cArtificial intelligence is transforming the way we work.\\u201d | \\u274c **No \\u2013 it does not mention a lazy dog** |\\n\\nSo, `file1.txt` satisfies the \\u201cquick brown fox\\u201d condition, but `file2.txt` does not satisfy the \\u201clazy dog\\u201d condition.\",\n",
      "        \"reasoning\": \"We read file1.txt and file2.txt. The user asked: \\\"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog.\\\" They want a check or confirmation. File1 contains quick brown fox. File2 does not mention lazy dog; it talks about AI. So file2 is not about lazy dog. We need to respond accordingly. Probably explain.\\n\\nWe can respond with a brief check: file1 is about quick brown fox, yes; file2 is not.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 436,\n",
      "    \"completion_tokens\": 236,\n",
      "    \"total_tokens\": 672\n",
      "  }\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200 (JSON):\n",
      "{\n",
      "  \"id\": \"chatcmpl-115\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1762531528,\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"system_fingerprint\": \"fp_ollama\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"**Check results**\\n\\n| File | Content mention | Meets requirement? |\\n|------|-----------------|--------------------|\\n| **file1.txt** | \\u201cThe quick brown fox jumps over the lazy dog.\\u201d | \\u2714 **Yes \\u2013 it contains the quick\\u2011brown\\u2011fox reference** |\\n| **file2.txt** | \\u201cArtificial intelligence is transforming the way we work.\\u201d | \\u274c **No \\u2013 it does not mention a lazy dog** |\\n\\nSo, `file1.txt` satisfies the \\u201cquick brown fox\\u201d condition, but `file2.txt` does not satisfy the \\u201clazy dog\\u201d condition.\",\n",
      "        \"reasoning\": \"We read file1.txt and file2.txt. The user asked: \\\"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog.\\\" They want a check or confirmation. File1 contains quick brown fox. File2 does not mention lazy dog; it talks about AI. So file2 is not about lazy dog. We need to respond accordingly. Probably explain.\\n\\nWe can respond with a brief check: file1 is about quick brown fox, yes; file2 is not.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 436,\n",
      "    \"completion_tokens\": 236,\n",
      "    \"total_tokens\": 672\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== End of HTTP Details ===\n",
      "\n",
      "Agent: **Check results**\n",
      "\n",
      "| File | Content mention | Meets requirement? |\n",
      "|------|-----------------|--------------------|\n",
      "| **file1.txt** | The quick brown fox jumps over the lazy dog. |  **Yes  it contains the quickbrownfox reference** |\n",
      "| **file2.txt** | Artificial intelligence is transforming the way we work. |  **No  it does not mention a lazy dog** |\n",
      "\n",
      "So, `file1.txt` satisfies the quick brown fox condition, but `file2.txt` does not satisfy the lazy dog condition.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import httpx\n",
    "import json\n",
    "from httpx._content import ByteStream\n",
    "\n",
    "# Restore any previous request patch from earlier runs\n",
    "if \"original_request\" in globals():\n",
    "    httpx.AsyncClient.request = original_request\n",
    "    del globals()[\"original_request\"]\n",
    "\n",
    "# Reset root handlers and silence everything except our custom httpx logs\n",
    "root_logger = logging.getLogger()\n",
    "for handler in list(root_logger.handlers):\n",
    "    root_logger.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Limit output to debug entries from httpx.logged_send_single_request\n",
    "class _HttpxFunctionFilter(logging.Filter):\n",
    "    def filter(self, record: logging.LogRecord) -> bool:\n",
    "        return record.funcName == \"logged_send_single_request\"\n",
    "    \n",
    "\n",
    "httpx_logger = logging.getLogger(\"httpx\")\n",
    "httpx_logger.handlers.clear()\n",
    "httpx_logger.setLevel(logging.DEBUG)\n",
    "httpx_logger.propagate = False\n",
    "\n",
    "httpx_handler = logging.StreamHandler()\n",
    "httpx_handler.setLevel(logging.DEBUG)\n",
    "httpx_handler.setFormatter(logging.Formatter('\\n[%(name)s - %(module)s] %(message)s'))\n",
    "# httpx_handler.addFilter(_HttpxFunctionFilter())\n",
    "httpx_logger.addHandler(httpx_handler)\n",
    "\n",
    "\n",
    "# Also enable openai library logging if available\n",
    "# logging.getLogger(\"openai\").setLevel(logging.DEBUG)\n",
    "\n",
    "if not hasattr(httpx.AsyncClient, \"_original_send_single_request\"):\n",
    "    httpx.AsyncClient._original_send_single_request = httpx.AsyncClient._send_single_request\n",
    "\n",
    "async def logged_send_single_request(self, request):\n",
    "    logger = logging.getLogger(\"httpx\")\n",
    "    if logger.isEnabledFor(logging.DEBUG):\n",
    "        stream = request.stream\n",
    "        if isinstance(stream, ByteStream):\n",
    "            body = stream._stream\n",
    "            logger.debug(\"Request: %s %s\", request.method, request.url)\n",
    "            if body:\n",
    "                try:\n",
    "                    body_str = body.decode(\"utf-8\")\n",
    "                    # Try to parse and pretty-print JSON\n",
    "                    try:\n",
    "                        json_obj = json.loads(body_str)\n",
    "                        pretty_json = json.dumps(json_obj, indent=2)\n",
    "                        logger.debug(\"\\tRequest body (JSON):\\n%s\", pretty_json)\n",
    "                    except json.JSONDecodeError:\n",
    "                        logger.debug(\"\\tRequest body (utf-8): %s\", body_str)\n",
    "                except UnicodeDecodeError:\n",
    "                    logger.debug(\"\\tRequest body (bytes): %s\", body)\n",
    "            else:\n",
    "                logger.debug(\"\\tRequest body: <empty>\")\n",
    "        else:\n",
    "            logger.debug(\"\\tRequest body not logged (stream type: %s)\", type(stream).__name__)\n",
    "    response = await httpx.AsyncClient._original_send_single_request(self, request)\n",
    "    if logger.isEnabledFor(logging.DEBUG):\n",
    "        # logger.debug(\"Response headers: %s\", dict(response.headers))\n",
    "        response_body = await response.aread()\n",
    "        try:\n",
    "            response_str = response_body.decode(\"utf-8\")\n",
    "            # Try to parse and pretty-print JSON\n",
    "            try:\n",
    "                json_obj = json.loads(response_str)\n",
    "                pretty_json = json.dumps(json_obj, indent=2)\n",
    "                logger.debug(f\"\\tResponse {response.status_code} (JSON):\\n{pretty_json}\")\n",
    "            except json.JSONDecodeError:\n",
    "                logger.debug(f\"\\tResponse {response.status_code}: {response_str}\")\n",
    "        except UnicodeDecodeError:\n",
    "            logger.debug(f\"\\tResponse {response.status_code} (bytes): {response_body}\")\n",
    "    return response\n",
    "\n",
    "if not getattr(httpx.AsyncClient, \"_logging_patch_applied\", False):\n",
    "    httpx.AsyncClient._send_single_request = logged_send_single_request\n",
    "    httpx.AsyncClient._logging_patch_applied = True\n",
    "\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "# tool = MCPStreamableHTTPTool(\n",
    "#             name=\"localhost MCP\",\n",
    "#             url=\"http://localhost:1337/mcp\",\n",
    "#         )\n",
    "llm = OpenAIChatClient(\n",
    "        api_key=\"ollama\", # Just a placeholder, Ollama doesn't require API key\n",
    "        # base_url=\"http://localhost:11434/v1\",\n",
    "        base_url=\"http://ollama.home/v1\",\n",
    "        model_id=\"gpt-oss:20b\",\n",
    "    )\n",
    "agent = llm.create_agent(\n",
    "        name=\"test_agent\",\n",
    "        instructions=\"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. \"\\\n",
    "            \"You can only respond using the tools available to you. Do not make up tool functionality. The tools will be\" \\\n",
    "                \"Provided to you in the prompt.\",\n",
    "        tools=[tool3],\n",
    "    )\n",
    "\n",
    "query = \"You must check that file 1 is about a quick brown fox and file 2 is about a lazy dog. \"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n=== HTTP Request/Response Details Below ===\\n\")\n",
    "result = await agent.run(query)\n",
    "print(f\"\\n=== End of HTTP Details ===\\n\")\n",
    "print(f\"Agent: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33adf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "\"\"\"\n",
    "Ollama with OpenAI Chat Client Example\n",
    "\n",
    "This sample demonstrates using Ollama models through OpenAI Chat Client by\n",
    "configuring the base URL to point to your local Ollama server for local AI inference.\n",
    "Ollama allows you to run large language models locally on your machine.\n",
    "\n",
    "Environment Variables:\n",
    "- OLLAMA_ENDPOINT: The base URL for your Ollama server (e.g., \"http://localhost:11434/v1/v1/\")\n",
    "- OLLAMA_MODEL: The model name to use (e.g., \"mistral\", \"llama3.2\", \"phi3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_weather(\n",
    "    location: Annotated[str, \"The location to get the weather for.\"],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}C.\"\n",
    "\n",
    "\n",
    "async def non_streaming_example() -> None:\n",
    "    \"\"\"Example of non-streaming response (get the complete result at once).\"\"\"\n",
    "    print(\"=== Non-streaming Response Example ===\")\n",
    "\n",
    "    agent = llm.create_agent(\n",
    "        name=\"WeatherAgent\",\n",
    "        instructions=\"You are a helpful weather agent.\",\n",
    "        tools=get_weather,\n",
    "    )\n",
    "\n",
    "    query = \"What's the weather like in Seattle?\"\n",
    "    print(f\"User: {query}\")\n",
    "    result = await agent.run(query)\n",
    "    print(f\"Agent: {result}\\n\")\n",
    "\n",
    "\n",
    "async def streaming_example() -> None:\n",
    "    \"\"\"Example of streaming response (get results as they are generated).\"\"\"\n",
    "    print(\"=== Streaming Response Example ===\")\n",
    "\n",
    "    agent = llm.create_agent(\n",
    "        name=\"WeatherAgent\",\n",
    "        instructions=\"You are a helpful weather agent.\",\n",
    "        tools=get_weather,\n",
    "    )\n",
    "\n",
    "    query = \"What's the weather like in Portland?\"\n",
    "    print(f\"User: {query}\")\n",
    "    print(\"Agent: \", end=\"\", flush=True)\n",
    "    async for chunk in agent.run_stream(query):\n",
    "        if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fa698bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Streaming Response Example ===\n",
      "User: What's the weather like in Portland?\n",
      "Agent: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful weather agent.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"What's the weather like in Portland?\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": true,\n",
      "  \"stream_options\": {\n",
      "    \"include_usage\": true\n",
      "  },\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"get_weather\",\n",
      "        \"description\": \"Get the weather for a given location.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"location\": {\n",
      "              \"description\": \"The location to get the weather for.\",\n",
      "              \"title\": \"Location\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"location\"\n",
      "          ],\n",
      "          \"title\": \"get_weather_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful weather agent.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"What's the weather like in Portland?\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": true,\n",
      "  \"stream_options\": {\n",
      "    \"include_usage\": true\n",
      "  },\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"get_weather\",\n",
      "        \"description\": \"Get the weather for a given location.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"location\": {\n",
      "              \"description\": \"The location to get the weather for.\",\n",
      "              \"title\": \"Location\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"location\"\n",
      "          ],\n",
      "          \"title\": \"get_weather_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"We\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" need\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" to\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" give\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" in\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Portland\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Lik\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"ely\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" get\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"_weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Which\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Portland\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"?\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Could\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" be\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" city\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" in\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" US\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" We'll\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" ask\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" or\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" default\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"?\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" We\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" can\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" with\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" location\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" \\\"\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"Port\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"land\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"\\\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Probably\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" will\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" return\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" data\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\\n\\n\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"We'll\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" proceed\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" to\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" get\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"_weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"tool_calls\":[{\"id\":\"call_1f038nw2\",\"index\":0,\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"arguments\":\"{\\\"location\\\":\\\"Portland\\\"}\"}}]},\"finish_reason\":\"tool_calls\"}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[],\"usage\":{\"prompt_tokens\":150,\"completion_tokens\":75,\"total_tokens\":225}}\n",
      "\n",
      "data: [DONE]\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful weather agent.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"What's the weather like in Portland?\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_1f038nw2\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"get_weather\",\n",
      "            \"arguments\": \"{\\\"location\\\":\\\"Portland\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_1f038nw2\",\n",
      "      \"content\": \"The weather in Portland is sunny with a high of 21\\u00b0C.\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": true,\n",
      "  \"stream_options\": {\n",
      "    \"include_usage\": true\n",
      "  },\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"get_weather\",\n",
      "        \"description\": \"Get the weather for a given location.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"location\": {\n",
      "              \"description\": \"The location to get the weather for.\",\n",
      "              \"title\": \"Location\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"location\"\n",
      "          ],\n",
      "          \"title\": \"get_weather_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"We\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" need\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" to\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" give\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" in\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Portland\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Lik\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"ely\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" get\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"_weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Which\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Portland\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"?\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Could\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" be\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" city\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" in\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" US\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" We'll\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" ask\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" or\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" default\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"?\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" We\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" can\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" with\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" location\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" \\\"\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"Port\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"land\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"\\\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Probably\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" will\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" return\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" data\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\\n\\n\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"We'll\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" proceed\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" to\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" call\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" get\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"_weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531528,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"tool_calls\":[{\"id\":\"call_1f038nw2\",\"index\":0,\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"arguments\":\"{\\\"location\\\":\\\"Portland\\\"}\"}}]},\"finish_reason\":\"tool_calls\"}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-271\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[],\"usage\":{\"prompt_tokens\":150,\"completion_tokens\":75,\"total_tokens\":225}}\n",
      "\n",
      "data: [DONE]\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx - 2223639304] \tRequest body (JSON):\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"You are a helpful weather agent.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"text\",\n",
      "          \"text\": \"What's the weather like in Portland?\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"tool_calls\": [\n",
      "        {\n",
      "          \"id\": \"call_1f038nw2\",\n",
      "          \"type\": \"function\",\n",
      "          \"function\": {\n",
      "            \"name\": \"get_weather\",\n",
      "            \"arguments\": \"{\\\"location\\\":\\\"Portland\\\"}\"\n",
      "          }\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"tool\",\n",
      "      \"tool_call_id\": \"call_1f038nw2\",\n",
      "      \"content\": \"The weather in Portland is sunny with a high of 21\\u00b0C.\"\n",
      "    }\n",
      "  ],\n",
      "  \"model\": \"gpt-oss:20b\",\n",
      "  \"stream\": true,\n",
      "  \"stream_options\": {\n",
      "    \"include_usage\": true\n",
      "  },\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"type\": \"function\",\n",
      "      \"function\": {\n",
      "        \"name\": \"get_weather\",\n",
      "        \"description\": \"Get the weather for a given location.\",\n",
      "        \"parameters\": {\n",
      "          \"properties\": {\n",
      "            \"location\": {\n",
      "              \"description\": \"The location to get the weather for.\",\n",
      "              \"title\": \"Location\",\n",
      "              \"type\": \"string\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"location\"\n",
      "          ],\n",
      "          \"title\": \"get_weather_input\",\n",
      "          \"type\": \"object\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - _client] HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"We\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" responded\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Great\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"The\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" in\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" Portland\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" is\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" sunny\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" with\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" a\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" high\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" of\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" \"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"21\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"C\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" If\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" you\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" need\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" more\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" details\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" (\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"like\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" wind\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\",\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" humidity\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\",\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" or\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" a\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" forecast\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" for\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" the\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" next\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" few\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" days\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"),\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" just\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" let\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" me\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" know\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"!\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"finish_reason\":\"stop\"}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[],\"usage\":{\"prompt_tokens\":194,\"completion_tokens\":55,\"total_tokens\":249}}\n",
      "\n",
      "data: [DONE]\n",
      "\n",
      "\n",
      "\n",
      "[httpx - 2223639304] \tResponse 200: data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"We\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" responded\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Great\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"The\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" weather\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" in\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" Portland\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" is\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" sunny\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" with\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" a\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" high\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" of\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" \"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"21\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"C\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\".\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" If\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" you\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" need\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" more\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" details\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" (\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"like\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" wind\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\",\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" humidity\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\",\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" or\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" a\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" forecast\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" for\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" the\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" next\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" few\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" days\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"),\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" just\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" let\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" me\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" know\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"!\"},\"finish_reason\":null}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"finish_reason\":\"stop\"}]}\n",
      "\n",
      "data: {\"id\":\"chatcmpl-360\",\"object\":\"chat.completion.chunk\",\"created\":1762531529,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[],\"usage\":{\"prompt_tokens\":194,\"completion_tokens\":55,\"total_tokens\":249}}\n",
      "\n",
      "data: [DONE]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in Portland is sunny with a high of 21C. If you weather in Portland is sunny with a high of 21C. If you need more details (like wind, humidity, or a forecast need more details (like wind, humidity, or a forecast for the next few days), just let me know!\n",
      "\n",
      " for the next few days), just let me know!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await streaming_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
