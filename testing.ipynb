{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eebfd717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import MCPStdioTool, MCPStreamableHTTPTool, MCPStdioTool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70fa7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = MCPStreamableHTTPTool(\n",
    "            name=\"Microsoft Learn MCP\",\n",
    "            url=\"https://learn.microsoft.com/api/mcp\",\n",
    "            # we don't require approval for microsoft_docs_search tool calls\n",
    "            # but we do for any other tool\n",
    "            # approval_mode={\"never_require_approval\": [\"microsoft_docs_search\"]},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa369a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool2 = MCPStdioTool(  \n",
    "    name=\"filesystem\",  \n",
    "    command=\"npx\",  \n",
    "    args=[\"-y\", \"@modelcontextprotocol/server-filesystem\", r\"C:\\Users\\blain\\Documents\"],  \n",
    "    description=\"File system operations\",  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9f02bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool3 = MCPStreamableHTTPTool(\n",
    "            name=\"localhost MCP\",\n",
    "            url=\"http://localhost:1337/mcp\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f4ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[openai._base_client _build_request]: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-d5bf08d9-86bf-4376-8c2f-9d9982779208', 'json_data': {'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': 'hello.'}]}], 'model': 'gpt-oss:20b', 'stream': False, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'speech_speak_to_users', 'description': 'Speaks to users using text-to-speech. Returns base64-encoded audio data.', 'parameters': {'properties': {'speech': {'title': 'Speech', 'type': 'string'}}, 'required': ['speech'], 'title': 'speech_speak_to_users_input', 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tasks_schedule_task', 'description': 'Schedule a new task for future execution by an AI agent.\\n\\nArgs:\\n    title: Short title for the task\\n    description: Detailed description of what needs to be done\\n    scheduled_time: When the task should be executed (ISO format: YYYY-MM-DDTHH:MM:SS)\\n    priority: Task priority level (low, medium, high, urgent)\\n    agent_context: Additional context or specific instructions for the AI agent\\n    tags: Comma-separated tags for task categorization\\n\\nReturns:\\n    Dictionary with task details and confirmation', 'parameters': {'properties': {'title': {'title': 'Title', 'type': 'string'}, 'description': {'title': 'Description', 'type': 'string'}, 'scheduled_time': {'title': 'Scheduled Time', 'type': 'string'}, 'priority': {'default': 'medium', 'title': 'Priority', 'type': 'string'}, 'agent_context': {'default': None, 'title': 'Agent Context', 'type': 'string'}, 'tags': {'default': None, 'title': 'Tags', 'type': 'string'}}, 'required': ['title', 'description', 'scheduled_time'], 'title': 'tasks_schedule_task_input', 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'tasks_view_tasks', 'description': 'View and filter previously scheduled tasks.\\n\\nArgs:\\n    status: Filter by task status (pending, in_progress, completed, cancelled)\\n    priority: Filter by priority level (low, medium, high, urgent)\\n    tag: Filter by a specific tag\\n    limit: Maximum number of tasks to return\\n    sort_by: Sort tasks by field (scheduled_time, created_at, priority)\\n\\nReturns:\\n    Dictionary with filtered and sorted task list', 'parameters': {'properties': {'status': {'default': None, 'title': 'Status', 'type': 'string'}, 'priority': {'default': None, 'title': 'Priority', 'type': 'string'}, 'tag': {'default': None, 'title': 'Tag', 'type': 'string'}, 'limit': {'default': None, 'title': 'Limit', 'type': 'string'}, 'sort_by': {'default': 'scheduled_time', 'title': 'Sort By', 'type': 'string'}}, 'title': 'tasks_view_tasks_input', 'type': 'object'}}}]}}\n",
      "\n",
      "[openai._base_client request]: Sending HTTP Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "[httpx logged_send_single_request]: Request body (utf-8): {\"messages\":[{\"role\":\"system\",\"content\":[{\"type\":\"text\",\"text\":\"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. You can only respond using the tools available to you. Do not make up tool functionality. The tools will beProvided to you in the prompt.\"}]},{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"hello.\"}]}],\"model\":\"gpt-oss:20b\",\"stream\":false,\"tool_choice\":\"auto\",\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"speech_speak_to_users\",\"description\":\"Speaks to users using text-to-speech. Returns base64-encoded audio data.\",\"parameters\":{\"properties\":{\"speech\":{\"title\":\"Speech\",\"type\":\"string\"}},\"required\":[\"speech\"],\"title\":\"speech_speak_to_users_input\",\"type\":\"object\"}}},{\"type\":\"function\",\"function\":{\"name\":\"tasks_schedule_task\",\"description\":\"Schedule a new task for future execution by an AI agent.\\n\\nArgs:\\n    title: Short title for the task\\n    description: Detailed description of what needs to be done\\n    scheduled_time: When the task should be executed (ISO format: YYYY-MM-DDTHH:MM:SS)\\n    priority: Task priority level (low, medium, high, urgent)\\n    agent_context: Additional context or specific instructions for the AI agent\\n    tags: Comma-separated tags for task categorization\\n\\nReturns:\\n    Dictionary with task details and confirmation\",\"parameters\":{\"properties\":{\"title\":{\"title\":\"Title\",\"type\":\"string\"},\"description\":{\"title\":\"Description\",\"type\":\"string\"},\"scheduled_time\":{\"title\":\"Scheduled Time\",\"type\":\"string\"},\"priority\":{\"default\":\"medium\",\"title\":\"Priority\",\"type\":\"string\"},\"agent_context\":{\"default\":null,\"title\":\"Agent Context\",\"type\":\"string\"},\"tags\":{\"default\":null,\"title\":\"Tags\",\"type\":\"string\"}},\"required\":[\"title\",\"description\",\"scheduled_time\"],\"title\":\"tasks_schedule_task_input\",\"type\":\"object\"}}},{\"type\":\"function\",\"function\":{\"name\":\"tasks_view_tasks\",\"description\":\"View and filter previously scheduled tasks.\\n\\nArgs:\\n    status: Filter by task status (pending, in_progress, completed, cancelled)\\n    priority: Filter by priority level (low, medium, high, urgent)\\n    tag: Filter by a specific tag\\n    limit: Maximum number of tasks to return\\n    sort_by: Sort tasks by field (scheduled_time, created_at, priority)\\n\\nReturns:\\n    Dictionary with filtered and sorted task list\",\"parameters\":{\"properties\":{\"status\":{\"default\":null,\"title\":\"Status\",\"type\":\"string\"},\"priority\":{\"default\":null,\"title\":\"Priority\",\"type\":\"string\"},\"tag\":{\"default\":null,\"title\":\"Tag\",\"type\":\"string\"},\"limit\":{\"default\":null,\"title\":\"Limit\",\"type\":\"string\"},\"sort_by\":{\"default\":\"scheduled_time\",\"title\":\"Sort By\",\"type\":\"string\"}},\"title\":\"tasks_view_tasks_input\",\"type\":\"object\"}}}]}\n",
      "\n",
      "[httpcore.connection atrace]: connect_tcp.started host='ollama.home' port=80 local_address=None timeout=5.0 socket_options=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: hello.\n",
      "\n",
      "=== HTTP Request/Response Details Below ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[httpcore.connection atrace]: connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x0000018A86B06060>\n",
      "\n",
      "[httpcore.http11 atrace]: send_request_headers.started request=<Request [b'POST']>\n",
      "\n",
      "[httpcore.http11 atrace]: send_request_headers.complete\n",
      "\n",
      "[httpcore.http11 atrace]: send_request_body.started request=<Request [b'POST']>\n",
      "\n",
      "[httpcore.http11 atrace]: send_request_body.complete\n",
      "\n",
      "[httpcore.http11 atrace]: receive_response_headers.started request=<Request [b'POST']>\n",
      "\n",
      "[httpcore.http11 atrace]: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'openresty'), (b'Date', b'Tue, 04 Nov 2025 02:37:59 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'468'), (b'Connection', b'keep-alive'), (b'X-Served-By', b'ollama.home')])\n",
      "\n",
      "[httpx _send_single_request]: HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "[httpcore.http11 atrace]: receive_response_body.started request=<Request [b'POST']>\n",
      "\n",
      "[httpcore.http11 atrace]: receive_response_body.complete\n",
      "\n",
      "[httpcore.http11 atrace]: response_closed.started\n",
      "\n",
      "[httpcore.http11 atrace]: response_closed.complete\n",
      "\n",
      "[httpx logged_send_single_request]: Response 200: b'{\"id\":\"chatcmpl-295\",\"object\":\"chat.completion\",\"created\":1762223879,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"Hello! How can I help you today?\",\"reasoning\":\"The user says \\\\\"hello.\\\\\" Probably wants a greeting. We can respond with a greeting text. No tool needed. No speech. Just normal text.\"},\"finish_reason\":\"stop\"}],\"usage\":{\"prompt_tokens\":472,\"completion_tokens\":49,\"total_tokens\":521}}\\n'\n",
      "\n",
      "[openai._base_client request]: HTTP Response: POST http://ollama.home/v1/chat/completions \"200 OK\" Headers({'server': 'openresty', 'date': 'Tue, 04 Nov 2025 02:37:59 GMT', 'content-type': 'application/json', 'content-length': '468', 'connection': 'keep-alive', 'x-served-by': 'ollama.home'})\n",
      "\n",
      "[openai._base_client request]: request_id: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== End of HTTP Details ===\n",
      "\n",
      "Agent: Hello! How can I help you today?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import httpx\n",
    "from httpx._content import ByteStream\n",
    "\n",
    "# Restore any previous request patch from earlier runs\n",
    "if \"original_request\" in globals():\n",
    "    httpx.AsyncClient.request = original_request\n",
    "    del globals()[\"original_request\"]\n",
    "\n",
    "# Reset logging handlers so we control formatting\n",
    "root_logger = logging.getLogger()\n",
    "for handler in list(root_logger.handlers):\n",
    "    root_logger.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.DEBUG, format='\\n[%(name)s - %(funcName)s]: %(message)s')\n",
    "# Ensure httpx logs adopt the simplified format\n",
    "httpx_logger = logging.getLogger(\"httpx\")\n",
    "httpx_logger.handlers.clear()\n",
    "httpx_logger.setLevel(logging.DEBUG)\n",
    "httpx_logger.propagate = True\n",
    "\n",
    "\n",
    "# Also enable openai library logging if available\n",
    "# logging.getLogger(\"openai\").setLevel(logging.DEBUG)\n",
    "\n",
    "if not hasattr(httpx.AsyncClient, \"_original_send_single_request\"):\n",
    "    httpx.AsyncClient._original_send_single_request = httpx.AsyncClient._send_single_request\n",
    "\n",
    "async def logged_send_single_request(self, request):\n",
    "    logger = logging.getLogger(\"httpx\")\n",
    "    if logger.isEnabledFor(logging.DEBUG):\n",
    "        stream = request.stream\n",
    "        if isinstance(stream, ByteStream):\n",
    "            body = stream._stream\n",
    "            if body:\n",
    "                try:\n",
    "                    logger.debug(\"Request body (utf-8): %s\", body.decode(\"utf-8\"))\n",
    "                except UnicodeDecodeError:\n",
    "                    logger.debug(\"Request body (bytes): %s\", body)\n",
    "            else:\n",
    "                logger.debug(\"Request body: <empty>\")\n",
    "        else:\n",
    "            logger.debug(\"Request body not logged (stream type: %s)\", type(stream).__name__)\n",
    "    response = await httpx.AsyncClient._original_send_single_request(self, request)\n",
    "    if logger.isEnabledFor(logging.DEBUG):\n",
    "        # logger.debug(\"Response headers: %s\", dict(response.headers))\n",
    "        logger.debug(f\"Response {response.status_code}: {await response.aread()}\")\n",
    "    return response\n",
    "\n",
    "if not getattr(httpx.AsyncClient, \"_logging_patch_applied\", False):\n",
    "    httpx.AsyncClient._send_single_request = logged_send_single_request\n",
    "    httpx.AsyncClient._logging_patch_applied = True\n",
    "\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "# tool = MCPStreamableHTTPTool(\n",
    "#             name=\"localhost MCP\",\n",
    "#             url=\"http://localhost:1337/mcp\",\n",
    "#         )\n",
    "llm = OpenAIChatClient(\n",
    "        api_key=\"ollama\", # Just a placeholder, Ollama doesn't require API key\n",
    "        # base_url=\"http://localhost:11434/v1\",\n",
    "        base_url=\"http://ollama.home/v1\",\n",
    "        model_id=\"gpt-oss:20b\",\n",
    "    )\n",
    "agent = llm.create_agent(\n",
    "        name=\"test_agent\",\n",
    "        instructions=\"You are a helpful agent. You use Model Context Protocol (MCP) tools to answer user questions. \"\\\n",
    "            \"You can only respond using the tools available to you. Do not make up tool functionality. The tools will be\" \\\n",
    "                \"Provided to you in the prompt.\",\n",
    "        tools=[tool3],\n",
    "    )\n",
    "\n",
    "query = \"hello.\"\n",
    "print(f\"User: {query}\")\n",
    "print(\"\\n=== HTTP Request/Response Details Below ===\\n\")\n",
    "result = await agent.run(query)\n",
    "print(f\"\\n=== End of HTTP Details ===\\n\")\n",
    "print(f\"Agent: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33adf473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "\n",
    "\"\"\"\n",
    "Ollama with OpenAI Chat Client Example\n",
    "\n",
    "This sample demonstrates using Ollama models through OpenAI Chat Client by\n",
    "configuring the base URL to point to your local Ollama server for local AI inference.\n",
    "Ollama allows you to run large language models locally on your machine.\n",
    "\n",
    "Environment Variables:\n",
    "- OLLAMA_ENDPOINT: The base URL for your Ollama server (e.g., \"http://localhost:11434/v1/v1/\")\n",
    "- OLLAMA_MODEL: The model name to use (e.g., \"mistral\", \"llama3.2\", \"phi3\")\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_weather(\n",
    "    location: Annotated[str, \"The location to get the weather for.\"],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}°C.\"\n",
    "\n",
    "\n",
    "async def non_streaming_example() -> None:\n",
    "    \"\"\"Example of non-streaming response (get the complete result at once).\"\"\"\n",
    "    print(\"=== Non-streaming Response Example ===\")\n",
    "\n",
    "    agent = llm.create_agent(\n",
    "        name=\"WeatherAgent\",\n",
    "        instructions=\"You are a helpful weather agent.\",\n",
    "        tools=get_weather,\n",
    "    )\n",
    "\n",
    "    query = \"What's the weather like in Seattle?\"\n",
    "    print(f\"User: {query}\")\n",
    "    result = await agent.run(query)\n",
    "    print(f\"Agent: {result}\\n\")\n",
    "\n",
    "\n",
    "async def streaming_example() -> None:\n",
    "    \"\"\"Example of streaming response (get results as they are generated).\"\"\"\n",
    "    print(\"=== Streaming Response Example ===\")\n",
    "\n",
    "    agent = llm.create_agent(\n",
    "        name=\"WeatherAgent\",\n",
    "        instructions=\"You are a helpful weather agent.\",\n",
    "        tools=get_weather,\n",
    "    )\n",
    "\n",
    "    query = \"What's the weather like in Portland?\"\n",
    "    print(f\"User: {query}\")\n",
    "    print(\"Agent: \", end=\"\", flush=True)\n",
    "    async for chunk in agent.run_stream(query):\n",
    "        if chunk.text:\n",
    "            print(chunk.text, end=\"\", flush=True)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa698bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Streaming Response Example ===\n",
      "User: What's the weather like in Portland?\n",
      "Agent: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "openai._base_client _build_request: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-48e07892-ae1a-4a54-b4ad-faed25e2f4f7', 'json_data': {'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a helpful weather agent.'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': \"What's the weather like in Portland?\"}]}], 'model': 'gpt-oss:20b', 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_weather', 'description': 'Get the weather for a given location.', 'parameters': {'properties': {'location': {'description': 'The location to get the weather for.', 'title': 'Location', 'type': 'string'}}, 'required': ['location'], 'title': 'get_weather_input', 'type': 'object'}}}]}}\n",
      "\n",
      "openai._base_client request: Sending HTTP Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "httpx logged_send_single_request: Request body (utf-8): {\"messages\":[{\"role\":\"system\",\"content\":[{\"type\":\"text\",\"text\":\"You are a helpful weather agent.\"}]},{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"What's the weather like in Portland?\"}]}],\"model\":\"gpt-oss:20b\",\"stream\":true,\"stream_options\":{\"include_usage\":true},\"tool_choice\":\"auto\",\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"description\":\"Get the weather for a given location.\",\"parameters\":{\"properties\":{\"location\":{\"description\":\"The location to get the weather for.\",\"title\":\"Location\",\"type\":\"string\"}},\"required\":[\"location\"],\"title\":\"get_weather_input\",\"type\":\"object\"}}}]}\n",
      "\n",
      "httpcore.http11 atrace: send_request_headers.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: send_request_headers.complete\n",
      "\n",
      "httpcore.http11 atrace: send_request_body.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: send_request_body.complete\n",
      "\n",
      "httpcore.http11 atrace: receive_response_headers.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'openresty'), (b'Date', b'Tue, 04 Nov 2025 02:36:33 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'X-Served-By', b'ollama.home')])\n",
      "\n",
      "httpx _send_single_request: HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "httpcore.http11 atrace: receive_response_body.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: receive_response_body.complete\n",
      "\n",
      "httpcore.http11 atrace: response_closed.started\n",
      "\n",
      "httpcore.http11 atrace: response_closed.complete\n",
      "\n",
      "httpx logged_send_single_request: Response 200: b'data: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"We\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" need\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" to\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" get\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" weather\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" for\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" Portland\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" We\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" need\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" to\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" use\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" get\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\"_weather\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\" function\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"reasoning\":\".\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\",\"tool_calls\":[{\"id\":\"call_z3hkd5ys\",\"index\":0,\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"arguments\":\"{\\\\\"location\\\\\":\\\\\"Portland\\\\\"}\"}}]},\"finish_reason\":\"tool_calls\"}]}\\n\\ndata: {\"id\":\"chatcmpl-732\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[],\"usage\":{\"prompt_tokens\":150,\"completion_tokens\":41,\"total_tokens\":191}}\\n\\ndata: [DONE]\\n\\n'\n",
      "\n",
      "openai._base_client request: HTTP Response: POST http://ollama.home/v1/chat/completions \"200 OK\" Headers({'server': 'openresty', 'date': 'Tue, 04 Nov 2025 02:36:33 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'x-served-by': 'ollama.home'})\n",
      "\n",
      "openai._base_client request: request_id: None\n",
      "\n",
      "agent_framework invoke: Function name: get_weather\n",
      "\n",
      "agent_framework invoke: Function arguments: {'location': 'Portland'}\n",
      "\n",
      "agent_framework invoke: Function get_weather succeeded.\n",
      "\n",
      "agent_framework invoke: Function result: The weather in Portland is sunny with a high of 20°C.\n",
      "\n",
      "openai._base_client _build_request: Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'idempotency_key': 'stainless-python-retry-fddae424-5cb3-479b-ba7f-3b1d553b105a', 'json_data': {'messages': [{'role': 'system', 'content': [{'type': 'text', 'text': 'You are a helpful weather agent.'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': \"What's the weather like in Portland?\"}]}, {'role': 'assistant', 'tool_calls': [{'id': 'call_z3hkd5ys', 'type': 'function', 'function': {'name': 'get_weather', 'arguments': '{\"location\":\"Portland\"}'}}]}, {'role': 'tool', 'tool_call_id': 'call_z3hkd5ys', 'content': 'The weather in Portland is sunny with a high of 20°C.'}], 'model': 'gpt-oss:20b', 'stream': True, 'stream_options': {'include_usage': True}, 'tool_choice': 'auto', 'tools': [{'type': 'function', 'function': {'name': 'get_weather', 'description': 'Get the weather for a given location.', 'parameters': {'properties': {'location': {'description': 'The location to get the weather for.', 'title': 'Location', 'type': 'string'}}, 'required': ['location'], 'title': 'get_weather_input', 'type': 'object'}}}]}}\n",
      "\n",
      "openai._base_client request: Sending HTTP Request: POST http://ollama.home/v1/chat/completions\n",
      "\n",
      "httpx logged_send_single_request: Request body (utf-8): {\"messages\":[{\"role\":\"system\",\"content\":[{\"type\":\"text\",\"text\":\"You are a helpful weather agent.\"}]},{\"role\":\"user\",\"content\":[{\"type\":\"text\",\"text\":\"What's the weather like in Portland?\"}]},{\"role\":\"assistant\",\"tool_calls\":[{\"id\":\"call_z3hkd5ys\",\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"arguments\":\"{\\\"location\\\":\\\"Portland\\\"}\"}}]},{\"role\":\"tool\",\"tool_call_id\":\"call_z3hkd5ys\",\"content\":\"The weather in Portland is sunny with a high of 20°C.\"}],\"model\":\"gpt-oss:20b\",\"stream\":true,\"stream_options\":{\"include_usage\":true},\"tool_choice\":\"auto\",\"tools\":[{\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"description\":\"Get the weather for a given location.\",\"parameters\":{\"properties\":{\"location\":{\"description\":\"The location to get the weather for.\",\"title\":\"Location\",\"type\":\"string\"}},\"required\":[\"location\"],\"title\":\"get_weather_input\",\"type\":\"object\"}}}]}\n",
      "\n",
      "httpcore.http11 atrace: send_request_headers.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: send_request_headers.complete\n",
      "\n",
      "httpcore.http11 atrace: send_request_body.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: send_request_body.complete\n",
      "\n",
      "httpcore.http11 atrace: receive_response_headers.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Server', b'openresty'), (b'Date', b'Tue, 04 Nov 2025 02:36:33 GMT'), (b'Content-Type', b'text/event-stream'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'X-Served-By', b'ollama.home')])\n",
      "\n",
      "httpx _send_single_request: HTTP Request: POST http://ollama.home/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\n",
      "httpcore.http11 atrace: receive_response_body.started request=<Request [b'POST']>\n",
      "\n",
      "httpcore.http11 atrace: receive_response_body.complete\n",
      "\n",
      "httpcore.http11 atrace: response_closed.started\n",
      "\n",
      "httpcore.http11 atrace: response_closed.complete\n",
      "\n",
      "httpx logged_send_single_request: Response 200: b'data: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"In\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" Portland\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" today\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\",\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" you\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\\xe2\\x80\\x99ll\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" enjoy\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" a\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" bright\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\",\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" sunny\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" day\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" with\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" temperatures\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" reaching\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" up\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" to\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" about\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" \"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"20\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\\xe2\\x80\\xaf\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\\xc2\\xb0C\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\".\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" It\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\\xe2\\x80\\x99s\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" a\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" nice\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" time\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" for\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" outdoor\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" activities\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\\xe2\\x80\\x94\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"just\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" remember\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" to\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" stay\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" hydrated\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" if\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" you\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223793,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\\xe2\\x80\\x99re\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223794,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" planning\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223794,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" to\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223794,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" be\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223794,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\" outside\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223794,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"!\"},\"finish_reason\":null}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223794,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[{\"index\":0,\"delta\":{\"role\":\"assistant\",\"content\":\"\"},\"finish_reason\":\"stop\"}]}\\n\\ndata: {\"id\":\"chatcmpl-272\",\"object\":\"chat.completion.chunk\",\"created\":1762223794,\"model\":\"gpt-oss:20b\",\"system_fingerprint\":\"fp_ollama\",\"choices\":[],\"usage\":{\"prompt_tokens\":194,\"completion_tokens\":49,\"total_tokens\":243}}\\n\\ndata: [DONE]\\n\\n'\n",
      "\n",
      "openai._base_client request: HTTP Response: POST http://ollama.home/v1/chat/completions \"200 OK\" Headers({'server': 'openresty', 'date': 'Tue, 04 Nov 2025 02:36:33 GMT', 'content-type': 'text/event-stream', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'x-served-by': 'ollama.home'})\n",
      "\n",
      "openai._base_client request: request_id: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Portland today, you’ll enjoy a bright, sunny day with temperatures reaching up to about 20 °C. It’s a nice time for outdoor activities—just remember to stay hydrated if you’re planning to be outside!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await streaming_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
